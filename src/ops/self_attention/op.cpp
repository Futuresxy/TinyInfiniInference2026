#include "op.hpp"
#include "../../core/llaisys_core.hpp"
#include "../../utils.hpp"
#include "cpu/self_attention_cpu.hpp"
namespace llaisys::ops {

void self_attention(tensor_t attn_val, tensor_t q, tensor_t k, tensor_t v, float scale) {
    // 1. 基础校验
    CHECK_SAME_DEVICE(attn_val, q, k, v);
    CHECK_SAME_DTYPE(attn_val->dtype(), q->dtype(), k->dtype(), v->dtype());
    
    // 2. 形状提取
    size_t seqlen   = q->shape()[0];
    size_t nhead    = q->shape()[1];
    size_t d        = q->shape()[2];
    size_t total_len = k->shape()[0];
    size_t nkvhead  = k->shape()[1];
    size_t dv       = v->shape()[2];

    // 3. 语义校验
    ASSERT(k->shape()[2] == d, "SelfAttention: Q and K head_dim mismatch.");
    ASSERT(v->shape()[0] == total_len, "SelfAttention: K and V total_len mismatch.");
    ASSERT(nhead % nkvhead == 0, "SelfAttention: nhead must be divisible by nkvhead (GQA).");
    ASSERT(attn_val->shape()[0] == seqlen && attn_val->shape()[1] == nhead && attn_val->shape()[2] == dv, 
           "SelfAttention: output shape mismatch.");

    // 4. 分发到 CPU
    if (attn_val->deviceType() == LLAISYS_DEVICE_CPU) {
        return cpu::self_attention(attn_val->data(), q->data(), k->data(), v->data(), 
                                  attn_val->dtype(), seqlen, total_len, nhead, nkvhead, d, dv, scale);
    }

    llaisys::core::context().setDevice(attn_val->deviceType(), attn_val->deviceId());
    switch (attn_val->deviceType()) {
        case LLAISYS_DEVICE_CPU:
            return cpu::self_attention(attn_val->data(), q->data(), k->data(), v->data(), 
                                      attn_val->dtype(), seqlen, total_len, nhead, nkvhead, d, dv, scale);
#ifdef ENABLE_NVIDIA_API
        case LLAISYS_DEVICE_NVIDIA:
            TO_BE_IMPLEMENTED();
            return;
#endif
        default:
            EXCEPTION_UNSUPPORTED_DEVICE;
    }
}

} // namespace llaisys::ops
